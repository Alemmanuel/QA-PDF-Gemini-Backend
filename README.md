# ğŸš€ PDF QA with Gemini Flash 1.5 + HuggingFace

Welcome to the ultimate, mind-blowing, next-generation PDF Question Answering CLI! This project leverages the power of Google Gemini Flash 1.5, HuggingFace, and LangChain to turn your boring PDFs into an interactive, AI-powered knowledge base. Ask anything, get instant answers, and feel like a true AI overlord! ğŸ¤–ğŸ“šâœ¨

## âœ¨ Features

- âš¡ **Supercharged PDF Ingestion:** Instantly process any PDF and generate high-quality embeddings using Google Generative AI.
- ğŸš€ **Lightning-fast QA:** Ask natural language questions about your PDF and get answers in seconds, powered by Gemini Flash 1.5.
- ğŸ’¾ **Persistent Vectorstore:** Your knowledge base is saved and ready for instant querying.
- ğŸ–¥ï¸ **CLI Simplicity:** No web UI, no distractions. Just pure, raw, terminal power.
- ğŸªŸ **Windows-Ready:** Designed and tested for Windows environments.
- ğŸ **Open Source Magic:** 100% Python, 100% hackable.

## ğŸ› ï¸ Requirements

- ğŸ Python 3.10+
- ğŸ“¦ pip
- ğŸ”‘ Google API Key (for Gemini)

## âš™ï¸ Installation

1. **Clone this repository:**
   ```bash
   git clone <your-repo-url>
   cd QA-PDF-Gemini
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up your environment variables:**
   - Copy the provided `.env` file or create one in the root directory:
     ```env
     LANGCHAIN_PROJECT=disabled
     ```

## âš¡ï¸ Environment Variable Setup

Before running the project, make sure to set your Google API key in your environment. You can do this in your terminal:

- On Linux/Mac:
  ```bash
  export GOOGLE_API_KEY=your_google_api_key_here
  ```
- On Windows:
  ```cmd
  set GOOGLE_API_KEY=your_google_api_key_here
  ```

Or simply edit the `.env` file as shown above.

## ğŸš¦ Usage

### ğŸ Start the CLI

```bash
python cli.py
```

You will see a beautiful banner and a list of available commands:

```
ğŸ§  PDF QA con Gemini Flash 1.5 + HuggingFace
Comandos disponibles:
  upload <ruta_pdf>   -> Procesa el PDF y genera embeddings (reemplaza vectorstore)
  ask <pregunta>      -> Haz una pregunta sobre el PDF
  exit                -> Salir
```

### ğŸ’¡ Commands

- ğŸ—‚ï¸ **upload <ruta_pdf>**
  - Example:
    ```bash
    upload docs/prueba-teoria.pdf
    ```
  - Processes the PDF, generates embeddings, and creates a new vectorstore. Uploading a new PDF will replace the previous vectorstore.

- â“ **ask <pregunta>**
  - Example:
    ```bash
    ask What is the main topic of the document?
    ask Â¿CuÃ¡l es el resumen del PDF?
    ```
  - Ask anything about your PDF! The AI will answer instantly. ğŸ¤–

- ğŸ‘‹ **exit**
  - Example:
    ```bash
    exit
    ```
  - Gracefully closes the CLI. You are now an AI master. ğŸ§™â€â™‚ï¸

## ğŸ§© Troubleshooting

- ğŸ›‘ **File lock errors on Windows:**
  - If you see errors about files being in use, simply close and reopen the CLI. Windows sometimes holds file locks longer than expected.
- ğŸ“„ **No PDF loaded:**
  - Make sure to upload a PDF before asking questions.
- ğŸ”‘ **API Key issues:**
  - Double-check your `.env` file and ensure your Google API key is valid.

## ğŸ§¬ How it Works (Under the Hood)

- ğŸ“„ **PDF Ingestion:** Uses PyMuPDF to load and split your PDF into chunks.
- ğŸ§  **Embeddings:** GoogleGenerativeAIEmbeddings creates vector representations of each chunk.
- ğŸ—ƒï¸ **Vectorstore:** ChromaDB stores the embeddings for fast retrieval.
- ğŸ¤– **QA Chain:** LangChain's RetrievalQA with Gemini Flash 1.5 answers your questions using the most relevant chunks.

## ğŸ† Why is this Project Awesome?

- It turns static PDFs into living, breathing, AI-powered documents. ğŸ¦¾
- It uses the latest in LLM and vector search technology. ğŸ§¬
- It's blazing fast, easy to use, and highly extensible. âš¡
- You can finally get answers from your PDFs without reading them! ğŸ“–â¡ï¸ğŸ¤–

## ğŸ¤ Contributing

Feel free to fork, hack, and submit PRs. The more, the merrier! ğŸ‰

## ğŸ“œ License

MIT. Use it, abuse it, make it better.

---

**Unleash the power of Gemini Flash 1.5 on your PDFs. Become the oracle of your own documents! ğŸ”®**

# ğŸ§  PDF QA Backend (Gemini Flash 1.5 + LangChain)

Este backend expone una API REST para procesar PDFs y responder preguntas usando Google Gemini Flash 1.5, LangChain y ChromaDB. EstÃ¡ diseÃ±ado para funcionar junto a un frontend web moderno (ver carpeta `../frontend`).

## ğŸš€ CaracterÃ­sticas

- Procesamiento de PDFs y generaciÃ³n de embeddings con Google Generative AI.
- Almacenamiento persistente de vectores con ChromaDB.
- Respuestas a preguntas en lenguaje natural usando LangChain y Gemini.
- Endpoints REST para integraciÃ³n sencilla con cualquier frontend.
- Compatible con despliegue en Render, Railway, etc.

## ğŸ“ Estructura de carpetas

```
backend/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ ingest.py      # Procesamiento de PDFs
â”‚   â”œâ”€â”€ qa.py          # LÃ³gica de preguntas y respuestas
â”‚   â”œâ”€â”€ vector.py      # Utilidades para vectorstore
â”‚   â””â”€â”€ __pycache__/
â”œâ”€â”€ cli.py             # CLI local (opcional)
â”œâ”€â”€ docs/              # PDFs de ejemplo (opcional)
â””â”€â”€ README.md          # Este archivo
```

En la raÃ­z del proyecto:
- `api.py` (el backend Flask, importa desde backend.core)
- `requirements.txt` (todas las dependencias de Python)
- `vectorstore/` (almacenamiento de embeddings y PDFs subidos)
- `frontend/` (interfaz web)

## âš™ï¸ InstalaciÃ³n y uso local

1. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

2. Ejecuta el backend:
   ```bash
   python api.py
   ```
   El backend quedarÃ¡ disponible en http://localhost:5000

3. (Opcional) Usa la CLI local:
   ```bash
   cd backend
   python cli.py
   ```

## ğŸŒ Endpoints principales

- `POST /upload`  
  Sube un PDF y lo procesa. Espera un campo `file` (multipart/form-data).
- `POST /ask`  
  EnvÃ­a una pregunta en JSON: `{ "question": "..." }` y recibe `{ "answer": "..." }`.

## ğŸ›°ï¸ Despliegue en Render

- Sube solo la carpeta backend, el archivo api.py y requirements.txt a tu repo.
- Comando de inicio recomendado:
  ```bash
  gunicorn api:app
  ```
- El frontend debe hacer fetch a la URL pÃºblica de tu backend (por ejemplo, https://tu-backend.onrender.com/ask).

## ğŸ”— IntegraciÃ³n con el frontend

- El frontend (carpeta `../frontend`) debe apuntar a la URL pÃºblica del backend en sus peticiones fetch.
- Ejemplo en `app.js`:
  ```js
  const UPLOAD_URL = 'https://tu-backend.onrender.com/upload';
  const ASK_URL = 'https://tu-backend.onrender.com/ask';
  ```

## ğŸ“ Notas

- La carpeta `vectorstore/` se crea automÃ¡ticamente y no debe subirse a GitHub.
- AsegÃºrate de tener tu API Key de Google en el entorno o en `.env`.
- Puedes modificar la lÃ³gica de ingestiÃ³n y QA en `core/ingest.py` y `core/qa.py`.

---

Â¿Dudas? Â¡Lee el README principal del proyecto o abre un issue!
